LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name    | Type                  | Params
--------------------------------------------------
0 | model   | TinyNetwork           | 802 K
1 | loss_fn | CrossEntropyCriterion | 0
--------------------------------------------------
802 K     Trainable params
0         Non-trainable params
802 K     Total params
3.210     Total estimated model params size (MB)
/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/haitt/workspaces/codes/nas/zebanas/train.py", line 32, in main
    trainer.fit(model, datamodule)
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 989, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self._run_sanity_check()
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1062, in _run_sanity_check
    val_loop.run()
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 134, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 391, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 403, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/mambaforge/envs/nas/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/workspaces/codes/nas/zebanas/zebanas/tasks/classification.py", line 43, in validation_step
    score = self.metric_fn(y_hat, y)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/haitt/workspaces/codes/nas/zebanas/zebanas/metrics/classifcation.py", line 6, in __call__
    preds = torch.argmax(preds, dim=1)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argmax(): argument 'input' (position 1) must be Tensor, not tuple
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Sanity Checking DataLoader 0:   0%|                                                                                                                              | 0/2 [00:00<?, ?it/s]